# Custom Render Pipeline

 

## Rendering

当Unity在渲染过程中每帧调用渲染管线（RP）实例时，会传递一个上下文结构，该结构提供了与本地引擎的连接，我们可以用它进行渲染。它还传递一个摄像机数组，因为场景中可以有多个活动摄像机。渲染管线的责任是按提供的顺序渲染所有这些摄像机。

### Camera Renderer

每个摄像机都会独立渲染。因此，不是让CustomRenderPipeline渲染所有摄像机，而是将这个责任转交给一个专门用于渲染单个摄像机的新类。将其命名为CameraRenderer，并为其提供一个公共的Render方法，该方法接受上下文和摄像机参数。让我们将这些参数存储在字段中以方便使用。

```
using UnityEngine;
using UnityEngine.Rendering;

public class CameraRenderer {

	ScriptableRenderContext context;

	Camera camera;

	public void Render (ScriptableRenderContext context, Camera camera) {
		this.context = context;
		this.camera = camera;
	}
}
```

让CustomRenderPipeline在创建时创建一个渲染器实例，然后在一个循环中使用它来渲染所有摄像机。

```
	CameraRenderer renderer = new CameraRenderer();

	protected override void Render (
		ScriptableRenderContext context, Camera[] cameras
	) {}
	
	protected override void Render (
		ScriptableRenderContext context, List<Camera> cameras
	) {
		for (int i = 0; i < cameras.Count; i++) {
			renderer.Render(context, cameras[i]);
		}
	}
```

我们的摄像机渲染器大致相当于Universal RP的可编程渲染器。这种方法将使未来能够轻松支持不同的摄像机渲染方式，例如第一人称视图和3D地图叠加视图，或者正向渲染与延迟渲染。但目前我们会以相同方式渲染所有摄像机。

### Drawing the Skybox

CameraRenderer.Render的工作是绘制其相机可以看到的所有几何体。为了清晰起见，将这个具体任务隔离到一个单独的DrawVisibleGeometry方法中。首先，让它绘制默认的天空盒，可以通过使用相机作为参数在上下文上调用DrawSkybox来实现。

```
	public void Render (ScriptableRenderContext context, Camera camera) {
		this.context = context;
		this.camera = camera;

		DrawVisibleGeometry();
	}

	void DrawVisibleGeometry () {
		context.DrawSkybox(camera);
	}
```

这还不会让天空盒出现。这是因为我们对上下文发布的命令被缓冲了。我们必须通过在DrawVisibleGeometry之后调用上下文的Submit方法来提交排队的工作以执行。

```
public void Render (ScriptableRenderContext context, Camera camera) {
		this.context = context;
		this.camera = camera;

		DrawVisibleGeometry();
		Submit();
	}

	void Submit () {
		context.Submit();
	}
```

天空盒最终出现在游戏窗口和场景窗口中。当您启用帧调试器时，还可以在其中看到与之相关的条目。它被列为Camera.RenderSkybox，其中有一个单独的Draw Mesh项，代表实际的绘制调用。这对应于游戏窗口的渲染。帧调试器不会报告其他窗口中的绘制。

请注意，当前相机的方向不会影响天空盒的渲染方式。我们将相机传递给DrawSkybox，但这仅用于确定是否应该绘制天空盒，这由相机的清除标志控制。

为了正确渲染天空盒和整个场景，我们必须设置视图投影矩阵。这个变换矩阵结合了相机的位置和方向（视图矩阵）以及相机的透视或正交投影（投影矩阵）。在着色器中，这被称为unity_MatrixVP，这是在绘制几何体时使用的着色器属性之一。您可以在帧调试器的ShaderProperties部分中检查这个矩阵，当选择一个绘制调用时。

目前，unity_MatrixVP矩阵始终相同。我们必须通过SetupCameraProperties方法将相机的属性应用于上下文，这将设置矩阵以及其他一些属性。在调用DrawVisibleGeometry之前，请在单独的Setup方法中执行此操作。

```
	public void Render (ScriptableRenderContext context, Camera camera) {
		this.context = context;
		this.camera = camera;

		Setup();
		DrawVisibleGeometry();
		Submit();
	}

	void Setup () {
		context.SetupCameraProperties(camera);
	}
```

### Command Buffers

上下文在实际渲染之前延迟渲染，我们在此之前配置它并添加命令以供稍后执行。一些任务，比如绘制天空盒，可以通过专用方法发出，但其他命令必须间接发出，通过单独的命令缓冲区。我们需要这样的缓冲区来绘制场景中的其他几何体。

为了获得一个缓冲区，我们需要创建一个新的CommandBuffer对象实例。我们只需要一个缓冲区，因此默认情况下为CameraRenderer创建一个并将其引用存储在字段中。还要为缓冲区命名，以便在帧调试器中识别它。可以命名为"Render Camera"。

```
	const string bufferName = "Render Camera";

	CommandBuffer buffer = new CommandBuffer {
		name = bufferName
	};
```

我们可以使用命令缓冲区来注入性能分析样本，这将显示在性能分析器和帧调试器中。这是通过在适当的时候调用BeginSample和EndSample来完成的，对于我们的情况，这是在Setup和Submit的开头。这两个方法必须提供相同的样本名称，我们将使用缓冲区的名称。

```
	void Setup () {
		buffer.BeginSample(bufferName);
		context.SetupCameraProperties(camera);
	}

	void Submit () {
		buffer.EndSample(bufferName);
		context.Submit();
	}
```

要执行缓冲区，使用上下文上的ExecuteCommandBuffer方法，并将缓冲区作为参数传递。这会复制缓冲区中的命令，但不会清除它，如果想要重新使用它，之后必须显式清除。因为执行和清除通常一起完成，所以添加一个同时执行和清除的方法是很方便的。

```
	void Setup () {
		buffer.BeginSample(bufferName);
		ExecuteBuffer();
		context.SetupCameraProperties(camera);
	}

	void Submit () {
		buffer.EndSample(bufferName);
		ExecuteBuffer();
		context.Submit();
	}

	void ExecuteBuffer () {
		context.ExecuteCommandBuffer(buffer);
		buffer.Clear();
	}
```

The *Camera.RenderSkyBox* sample now gets nested inside *Render Camera*.

### Clearing the Render Target

无论我们绘制什么，最终都会呈现到相机的渲染目标上，该目标默认情况下是帧缓冲，但也可以是渲染纹理。无论之前绘制到该目标的内容仍然存在，这可能会干扰我们当前正在渲染的图像。为了确保正确的渲染，我们必须清除渲染目标以清除其旧内容。这可以通过在命令缓冲区中的Setup方法中调用ClearRenderTarget来完成。

CommandBuffer.ClearRenderTarget至少需要三个参数。前两个参数指示是否应清除深度和颜色数据，对于两者都是true。第三个参数是用于清除的颜色，我们将使用Color.clear。

```
	void Setup () {
		buffer.BeginSample(bufferName);
		buffer.ClearRenderTarget(true, true, Color.clear);
		ExecuteBuffer();
		context.SetupCameraProperties(camera);
	}
```

现在，帧调试器显示了一个清除操作的Draw GL条目，它嵌套在Render Camera的附加级别中。这是因为ClearRenderTarget将清除包装在一个与命令缓冲区名称相关的样本中。我们可以通过在开始我们自己的样本之前进行清除来摆脱多余的嵌套。这将导致两个相邻的Render Camera样本范围，它们将被合并在一起。

```c#
	void Setup () {
		buffer.ClearRenderTarget(true, true, Color.clear);
		buffer.BeginSample(bufferName);
		//buffer.ClearRenderTarget(true, true, Color.clear);
		ExecuteBuffer();
		context.SetupCameraProperties(camera);
	}
```

但这不是清除渲染目标的最高效方式。之所以使用这种方法，是因为我们在设置相机属性之前进行了清除。如果我们交换这两个步骤的顺序，就可以采用更快速的清除方式。

```
	void Setup () {
		context.SetupCameraProperties(camera);
		buffer.ClearRenderTarget(true, true, Color.clear);
		buffer.BeginSample(bufferName);
		ExecuteBuffer();
		//context.SetupCameraProperties(camera);
	}
```

现在我们看到了Clear（颜色+Z+模板），这表示颜色和深度缓冲区都被清除。Z代表深度缓冲区，而模板数据是该缓冲区的一部分。

### Culling

我们目前只能看到天空盒，而看不到我们放在场景中的任何对象。我们不是绘制每个对象，而是只渲染那些对相机可见的对象。我们通过从场景中获取具有渲染器组件的所有对象开始，然后将那些超出相机视锥体外部的对象进行剔除来实现这一点。

确定哪些对象可以被剔除需要我们跟踪多个相机设置和矩阵，为此我们可以使用ScriptableCullingParameters结构。而不是手动填充它，我们可以在相机上调用TryGetCullingParameters方法。它返回参数是否能够成功检索，因为它可能会因为相机设置的退化而失败。为了获取参数数据，我们必须将它作为输出参数提供，通过在其前面写出来。请在一个单独的Cull方法中执行此操作，该方法返回成功或失败。

```
	bool Cull () {
		ScriptableCullingParameters p
		if (camera.TryGetCullingParameters(out p)) {
			return true;
		}
		return false;
	}
```

当用作输出参数时，可以在参数列表内联变量声明，所以我们可以这样做。

```
	public void Render (ScriptableRenderContext context, Camera camera) {
		this.context = context;
		this.camera = camera;

		if (!Cull()) {
			return;
		}

		Setup();
		DrawVisibleGeometry();
		Submit();
	}
```

如果成功的话，实际的剔除是通过在上下文上调用Cull来完成的，这将产生一个CullingResults结构。如果成功，请在Cull方法中执行此操作并将结果存储在一个字段中。在这种情况下，我们必须将剔除参数作为引用参数传递，通过在其前面写上"ref"。

```
	CullingResults cullingResults;

	…
	
	bool Cull () {
		if (camera.TryGetCullingParameters(out ScriptableCullingParameters p)) {
			cullingResults = context.Cull(ref p);
			return true;
		}
		return false;
	}
```


"ref"关键字的工作方式与"out"相似，不同之处在于方法不需要对其进行赋值。调用方法的人负责先正确初始化该值。因此，它可用于输入，也可以用于可选的输出。

在这种情况下，"ref"被用作一种优化，以防止传递ScriptableCullingParameters结构的副本，因为这个结构可能相当大。它是一个结构而不是对象，这也是另一种优化，以防止内存分配

### Drawing Geometry

一旦我们知道哪些物体是可见的，我们可以继续渲染这些物体。这是通过在上下文上调用DrawRenderers，将剔除结果作为参数传递给它，并告诉它要使用哪些渲染器来完成的。除此之外，我们还必须提供绘制设置和过滤设置。这两者都是结构体——DrawingSettings和FilteringSettings，最初我们将使用它们的默认构造函数。这两者都必须通过引用传递。请在DrawVisibleGeometry中执行此操作，位于绘制天空盒之前。

```
	void DrawVisibleGeometry () {
		var drawingSettings = new DrawingSettings();
		var filteringSettings = new FilteringSettings();

		context.DrawRenderers(
			cullingResults, ref drawingSettings, ref filteringSettings
		);

		context.DrawSkybox(camera);
	}
```

我们目前还看不到任何东西，因为我们还必须指示允许哪种着色器通道。由于在本教程中仅支持不受光照影响的着色器，因此我们必须获取SRPDefaultUnlit通道的着色器标签ID，我们可以在一个静态字段中缓存它以避免重复获取。

```
static ShaderTagId unlitShaderTagId = new ShaderTagId("SRPDefaultUnlit");
```

将它作为DrawingSettings构造函数的第一个参数提供，同时提供一个新的SortingSettings结构值。将相机传递给排序设置的构造函数，因为它用于确定是使用正交还是基于距离的排序。

```
	void DrawVisibleGeometry () {
		var sortingSettings = new SortingSettings(camera);
		var drawingSettings = new DrawingSettings(
			unlitShaderTagId, sortingSettings
		);
		…
	}
```

此外，我们还必须指示允许哪些渲染队列。将`RenderQueueRange.all`传递给FilteringSettings构造函数，以包括所有内容。

```
		var filteringSettings = new FilteringSettings(RenderQueueRange.all);
```

只有使用不受光照影响的着色器的可见对象才会被绘制。所有绘制调用都列在帧调试器中，分组在RenderLoop.Draw下。透明对象似乎有一些奇怪的情况，但首先让我们看看对象绘制的顺序。帧调试器显示了这个，并且您可以通过依次选择或使用箭头键来逐步执行绘制调用。

绘制顺序似乎是杂乱的。我们可以通过设置排序设置的criteria属性来强制特定的绘制顺序。让我们使用SortingCriteria.CommonOpaque。

```
		var sortingSettings = new SortingSettings(camera) {
			criteria = SortingCriteria.CommonOpaque
		};
```

现在对象基本上是从前到后绘制的，这对于不透明对象来说是理想的。如果某物最终被绘制在其他物体后面，那么它的隐藏片段可以被跳过，从而加快渲染速度。通用不透明排序选项还考虑了一些其他标准，包括渲染队列和材质。

### Drawing Opaque and Transparent Geometry Separately


帧调试器显示了透明对象被绘制，但天空盒覆盖了除不透明对象前面的一切。天空盒在不透明几何体之后绘制，因此它的所有隐藏片段都可以被跳过，但它会覆盖透明几何。这是因为透明着色器不写入深度缓冲区。它们不会隐藏在它们后面的任何东西，因为我们可以透过它们看到。解决方案是首先绘制不透明对象，然后是天空盒，最后是透明对象。

我们可以通过切换到`RenderQueueRange.opaque`来在最初的`DrawRenderers`调用中排除透明对象。

```
		var filteringSettings = new FilteringSettings(RenderQueueRange.opaque);
```

然后在绘制天空盒之后再次调用`DrawRenderers`。但在这样做之前，将渲染队列范围更改为`RenderQueueRange.transparent`。同时，将排序标准更改为`SortingCriteria.CommonTransparent`，并再次设置绘制设置的排序。这将颠倒透明对象的绘制顺序。

```
		context.DrawSkybox(camera);

		sortingSettings.criteria = SortingCriteria.CommonTransparent;
		drawingSettings.sortingSettings = sortingSettings;
		filteringSettings.renderQueueRange = RenderQueueRange.transparent;

		context.DrawRenderers(
			cullingResults, ref drawingSettings, ref filteringSettings
		);
```

## Editor Rendering

我们的渲染管线(RP)正确绘制不受光照影响的对象，但还有一些方法可以改善在Unity编辑器中使用它的体验。

### Drawing Legacy Shaders

因为我们的渲染管线只支持不受光照影响的着色器通道，使用不同通道的对象不会被渲染，使它们不可见。尽管这是正确的，但它隐藏了场景中一些对象使用了错误的着色器的事实。因此，让我们无论如何都将它们渲染出来，但分开渲染。

如果有人从一个默认的Unity项目开始，然后后来切换到我们的渲染管线，那么他们的场景中可能有一些使用错误着色器的对象。为了涵盖所有Unity的默认着色器，我们需要使用Always、ForwardBase、PrepassBase、Vertex、VertexLMRGBM和VertexLM的着色器标签ID。将这些ID保存在一个静态数组中。

```
	static ShaderTagId[] legacyShaderTagIds = {
		new ShaderTagId("Always"),
		new ShaderTagId("ForwardBase"),
		new ShaderTagId("PrepassBase"),
		new ShaderTagId("Vertex"),
		new ShaderTagId("VertexLMRGBM"),
		new ShaderTagId("VertexLM")
	};
```

在可见几何体之后，绘制所有不支持的着色器，从第一个通道开始，可以将其放在一个单独的方法中。由于这些是无效的通道，结果无论如何都会出错，所以我们不关心其他设置。我们可以通过`FilteringSettings.defaultValue`属性获取默认的过滤设置。

```
	public void Render (ScriptableRenderContext context, Camera camera) {
		…

		Setup();
		DrawVisibleGeometry();
		DrawUnsupportedShaders();
		Submit();
	}

	…

	void DrawUnsupportedShaders () {
		var drawingSettings = new DrawingSettings(
			legacyShaderTagIds[0], new SortingSettings(camera)
		);
		var filteringSettings = FilteringSettings.defaultValue;
		context.DrawRenderers(
			cullingResults, ref drawingSettings, ref filteringSettings
		);
	}
```

我们可以通过在绘制设置上使用`SetShaderPassName`，使用绘制顺序索引和标签作为参数来绘制多个通道。从数组中的第二个通道开始执行此操作，因为我们已经在构建绘制设置时设置了第一个通道。

```
		var drawingSettings = new DrawingSettings(
			legacyShaderTagIds[0], new SortingSettings(camera)
		);
		for (int i = 1; i < legacyShaderTagIds.Length; i++) {
			drawingSettings.SetShaderPassName(i, legacyShaderTagIds[i]);
		}
```

使用标准着色器渲染的对象已经可见，但它们现在是纯黑色，因为我们的渲染管线(RP)尚未为它们设置所需的着色器属性。

### Error Material

为了明确指示哪些对象使用不支持的着色器，我们将使用Unity的错误着色器将它们绘制出来。构建一个新的材质，将该着色器作为参数传递，可以通过使用Hidden/InternalErrorShader字符串作为参数来调用Shader.Find来找到它。通过一个静态字段缓存这个材质，这样我们就不会在每一帧都创建一个新的。然后将它分配给绘制设置的`overrideMaterial`属性。

```
	static Material errorMaterial;

	…

	void DrawUnsupportedShaders () {
		if (errorMaterial == null) {
			errorMaterial =
				new Material(Shader.Find("Hidden/InternalErrorShader"));
		}
		var drawingSettings = new DrawingSettings(
			legacyShaderTagIds[0], new SortingSettings(camera)
		) {
			overrideMaterial = errorMaterial
		};
		…
	}
```

### Partial Class

绘制无效对象对于开发是有用的，但不适用于发布的应用程序。因此，让我们将CameraRenderer的所有仅限于编辑器的代码放在一个单独的部分类文件中。首先，复制原始的CameraRenderer脚本资源，并将其重命名为CameraRenderer.Editor。

然后，将原始的CameraRenderer转换为部分类，并从中删除标签数组、错误材质和DrawUnsupportedShaders方法。

```
public partial class CameraRenderer { … }
```

Clean the other partial class file so it only contains what we removed from the other.

```
partial class CameraRenderer {
partial void DrawUnsupportedShaders ();
#if UNITY_EDITOR

	static ShaderTagId[] legacyShaderTagIds = { … }
	};

	static Material errorMaterial;

	void DrawUnsupportedShaders () { … }

#endif
}
```

### Drawing Gizmos

目前，我们的渲染管线(RP)不会绘制gizmos，无论是在场景窗口还是在游戏窗口（如果已启用）中。

我们可以通过调用`UnityEditor.Handles.ShouldRenderGizmos`来检查是否应该绘制gizmos。如果应该绘制，我们需要使用相机作为参数调用上下文的`DrawGizmos`方法，另外还需要传递一个第二个参数，指示应该绘制哪个gizmo子集。有两个子集，用于图像效果之前和之后。因为我们在这个阶段不支持图像效果，所以我们将同时调用两者。请在一个新的仅编辑器用的`DrawGizmos`方法中执行此操作。

```
using UnityEditor;
using UnityEngine;
using UnityEngine.Rendering;

partial class CameraRenderer {
	
	partial void DrawGizmos ();

	partial void DrawUnsupportedShaders ();

#if UNITY_EDITOR

	…

	partial void DrawGizmos () {
		if (Handles.ShouldRenderGizmos()) {
			context.DrawGizmos(camera, GizmoSubset.PreImageEffects);
			context.DrawGizmos(camera, GizmoSubset.PostImageEffects);
		}
	}

	partial void DrawUnsupportedShaders () { … }

#endif
}
```

The gizmos should be drawn after everything else.

```
	public void Render (ScriptableRenderContext context, Camera camera) {
		…

		Setup();
		DrawVisibleGeometry();
		DrawUnsupportedShaders();
		DrawGizmos();
		Submit();
	}
```

### Drawing Unity UI

还需要注意的一件事是Unity的游戏中用户界面。例如，通过GameObject / UI / Button添加一个简单的UI按钮。它会显示在游戏窗口中，但不会显示在场景窗口中。

The frame debugger shows us that the UI is rendered separately, not by our RP.

![img](https://catlikecoding.com/unity/tutorials/custom-srp/custom-render-pipeline/editor-rendering/ui-debugger.png)

至少在Canvas组件的渲染模式设置为Screen Space - Overlay时是这样，这是默认设置。将其更改为Screen Space - Camera，并将主相机用作其渲染相机，将使其成为透明几何的一部分。

UI在场景窗口中始终使用World Space模式进行渲染，这通常导致它非常大。虽然我们可以通过场景窗口编辑UI，但它不会被绘制。

在为场景窗口渲染时，我们必须将UI明确添加到世界几何中，方法是通过使用相机作为参数调用`ScriptableRenderContext.EmitWorldGeometryForSceneView`。请在一个新的仅编辑器用的`PrepareForSceneWindow`方法中执行此操作。我们在场景相机的`cameraType`属性等于`CameraType.SceneView`时进行渲染。

```
	partial void PrepareForSceneWindow ();

#if UNITY_EDITOR

	…

	partial void PrepareForSceneWindow () {
		if (camera.cameraType == CameraType.SceneView) {
			ScriptableRenderContext.EmitWorldGeometryForSceneView(camera);
		}
	}
```

```
		PrepareForSceneWindow();
		if (!Cull()) {
			return;
		}
```

## Multiple Cameras

在场景中可以有多个活动相机。如果有多个相机，我们必须确保它们能够一起正常工作。

### Two Cameras

每个相机都有一个深度值，默认主相机的深度值为-1。它们按深度值递增的顺序进行渲染。要查看这一点，复制主相机，将其重命名为Secondary Camera，并将其深度设置为0。此外，给它分配另一个标签也是一个好主意，因为MainCamera应该只被一个相机使用。

现在场景被渲染了两次。由于在两次渲染之间清除了渲染目标，因此结果图像仍然相同。帧调试器显示了这一点，但由于相邻的带有相同名称的示例范围会被合并，所以我们最终只有一个Render Camera范围。

如果每个相机都有自己的范围，那会更清晰。为了实现这一点，添加一个仅编辑器用的`PrepareBuffer`方法，使缓冲区的名称等于相机的名称。

```
	partial void PrepareBuffer ();

#if UNITY_EDITOR

	…
	
	partial void PrepareBuffer () {
		buffer.name = camera.name;
	}

#endif
```

Invoke it before we prepare the scene window.

```
		PrepareBuffer();
		PrepareForSceneWindow();
```

### Dealing with Changing Buffer Names


虽然帧调试器现在显示每个相机的单独示例层次结构，但当我们进入播放模式时，Unity的控制台将充满警告消息，提示我们BeginSample和EndSample的计数必须匹配。它会因为我们为示例和缓冲区使用不同的名称而感到困惑。此外，每次访问相机的名称属性时都会分配内存，因此我们不希望在构建中这样做。

为了解决这两个问题，我们将添加一个`SampleName`字符串属性。如果我们在编辑器中，我们会在`PrepareBuffer`中设置它，同时设置缓冲区的名称，否则它只是`Render Camera`字符串的一个常量别名。

```
#if UNITY_EDITOR

	…

	string SampleName { get; set; }
	
	…
	
	partial void PrepareBuffer () {
		buffer.name = SampleName = camera.name;
	}

#else

	const string SampleName = bufferName;

#endif
```

Use `SampleName` for the sample in `Setup` and `Submit`.

```
	void Setup () {
		context.SetupCameraProperties(camera);
		buffer.ClearRenderTarget(true, true, Color.clear);
		buffer.BeginSample(SampleName);
		ExecuteBuffer();
	}

	void Submit () {
		buffer.EndSample(SampleName);
		ExecuteBuffer();
		context.Submit();
	}
```

我们可以通过检查Profiler来看到差异——通过Window / Analysis / Profiler打开，并首先在编辑器中播放。切换到Hierarchy模式，按GC Alloc列进行排序。您会看到两次GC.Alloc的分配条目，总共分配了100字节，这是由于获取相机名称导致的。在下方，您将看到这些名称显示为示例：Main Camera和Secondary Camera。

接下来，创建一个开发构建，启用Development Build和Autoconnect Profiler选项。播放构建并确保Profiler已连接并记录。在这种情况下，我们不会获得100字节的分配，而是得到一个名为Render Camera的单一示例。

我们可以通过将相机名称的获取包装在一个名为Editor Only的Profiler示例中，以明确指出我们只在编辑器中分配内存，而在构建中不分配内存。在这种情况下，我们需要从UnityEngine.Profiling命名空间中调用Profiler.BeginSample和Profiler.EndSample。只有BeginSample需要传递名称。

```
using UnityEditor;
using UnityEngine;
using UnityEngine.Profiling;
using UnityEngine.Rendering;

partial class CameraRenderer {

	…
	
#if UNITY_EDITOR

	…

	partial void PrepareBuffer () {
		Profiler.BeginSample("Editor Only");
		buffer.name = SampleName = camera.name;
		Profiler.EndSample();
	}

#else

	string SampleName => bufferName;

#endif
}
```

### Layers

相机还可以配置为只看到特定图层上的物体。这是通过调整它们的Culling Mask完成的。为了看到这个过程，让我们将所有使用标准着色器的物体移动到Ignore Raycast图层。

Exclude that layer from the culling mask of *Main Camera*.

And make it the only layer seen by *Secondary Camera*.

Because *Secondary Camera* renders last we end up seeing only the invalid objects.

### Clear Flags

我们可以通过调整第二个相机的清除标志来组合两个相机的结果。它们由CameraClearFlags枚举定义，可以通过相机的clearFlags属性检索。在清除之前在Setup中执行此操作。

```
	void Setup () {
		context.SetupCameraProperties(camera);
		CameraClearFlags flags = camera.clearFlags;
		buffer.ClearRenderTarget(true, true, Color.clear);
		buffer.BeginSample(SampleName);
		ExecuteBuffer();
	}
```

CameraClearFlags枚举定义了四个值。从1到4，它们分别是Skybox、Color、Depth和Nothing。这实际上不是独立的标志值，而代表了清除的递减量。深度缓冲区必须在所有情况下清除，除了最后一个情况，因此当flags值最多为Depth时。

```
		buffer.ClearRenderTarget(
			flags <= CameraClearFlags.Depth, true, Color.clear
		);
```

实际上，我们只需要在flags设置为Color时清除颜色缓冲区，因为在Skybox的情况下，我们最终会替换所有先前的颜色数据。然而，

```
		buffer.ClearRenderTarget(
			flags <= CameraClearFlags.Depth,
			flags == CameraClearFlags.Color,
			Color.clear
		);
```

对于Unity 2022，我更改了这个行为，始终清除颜色，除非明确告诉不清除，因为渲染目标可能包含NaN和无穷大值，这可能会导致混合伪像。此外，帧调试器可能显示随机数据，这会使调试变得困难。

```
flags <= CameraClearFlags.Color
```

如果我们要清除到纯色，我们必须使用相机的背景颜色。但因为我们在线性颜色空间中进行渲染，所以我们需要将该颜色转换为线性空间，因此我们最终需要`camera.backgroundColor.linear`。在所有其他情况下，颜色都不重要，所以我们可以使用`Color.clear`。

```
		buffer.ClearRenderTarget(
			flags <= CameraClearFlags.Depth,
			flags == CameraClearFlags.Color,
			flags == CameraClearFlags.Color ?
				camera.backgroundColor.linear : Color.clear
		);
```

因为Main Camera是第一个渲染的，所以它的Clear Flags应设置为Skybox或Color。当帧调试器启用时，我们总是从一个清除缓冲开始，但一般情况下不能保证这一点。

Secondary Camera的清除标志确定了两个相机的渲染如何组合。在天空盒或颜色的情况下，先前的结果会被完全替换。当仅清除深度时，Secondary Camera会正常渲染，只是不绘制天空盒，因此以前的结果会显示为背景。当不清除任何内容时，深度缓冲区会保留，因此不照明的对象最终会遮挡无效对象，就好像它们是由同一台相机绘制的一样。然而，由前一个相机绘制的透明对象没有深度信息，因此会被覆盖，就像之前的天空盒一样。

通过调整相机的Viewport Rect，还可以将渲染区域减小到整个渲染目标的一部分。渲染目标的其余部分保持不受影响。在这种情况下，清除使用Hidden/InternalClear着色器完成。模板缓冲用于限制渲染到视口区域。

请注意，每帧渲染多个相机意味着必须多次执行剔除、设置、排序等操作。通常，使用每个唯一视角一个相机是效率最高的方法。